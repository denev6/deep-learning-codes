{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denev6/practice/blob/main/transformer/RoBERTa_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt9LGLSXyZpq",
        "outputId": "61a245f5-ebde-4ee1-f8fe-a36282628b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.15\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qXlXpiWjwG8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SskIfXoWvyS_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    RobertaTokenizerFast,\n",
        "    RobertaForSequenceClassification,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLO55TxdfYuV"
      },
      "outputs": [],
      "source": [
        "CWD = \"/content/drive/MyDrive\"\n",
        "\n",
        "\n",
        "def join_path(*args):\n",
        "    return os.path.join(CWD, *args)\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "TRAIN_CSV = join_path(\"data\", \"train.csv\")\n",
        "TEST_CSV = join_path(\"data\", \"test.csv\")\n",
        "MODEL = \"tae898/emoberta-base\"\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "TRAIN_ARGS = TrainingArguments(\n",
        "    output_dir=join_path(\"emoberta\"),\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SPq3wijdEGA"
      },
      "source": [
        "# Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97XA-GEZmc6s"
      },
      "outputs": [],
      "source": [
        "class LabelEncoder(object):\n",
        "    def __init__(self):\n",
        "        self._targets = [\n",
        "            \"neutral\",\n",
        "            \"joy\",\n",
        "            \"surprise\",\n",
        "            \"anger\",\n",
        "            \"sadness\",\n",
        "            \"disgust\",\n",
        "            \"fear\",\n",
        "        ]\n",
        "        self.target_size = len(self._targets)\n",
        "\n",
        "    def encode(self, labels):\n",
        "        labels = [self._targets.index(lb) for lb in labels]\n",
        "        return labels\n",
        "\n",
        "    def decode(self, labels):\n",
        "        labels = [self._targets[lb] for lb in labels]\n",
        "        return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPDUHfujx2NN"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFZRDzdWkoTz"
      },
      "outputs": [],
      "source": [
        "train_csv = pd.read_csv(TRAIN_CSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCp43NZrqBJ7"
      },
      "outputs": [],
      "source": [
        "roberta_tokenizer = RobertaTokenizerFast.from_pretrained(MODEL, truncation=True)\n",
        "label_encoder = LabelEncoder()\n",
        "label_size = label_encoder.target_size\n",
        "train_csv[\"Target\"] = label_encoder.encode(train_csv[\"Target\"])\n",
        "\n",
        "train_id = len(train_csv) // 8\n",
        "dialogue_id = train_csv.loc[train_id, \"Dialogue_ID\"]\n",
        "df_train, df_eval = train_csv[: train_id + 1], train_csv[train_id:]\n",
        "\n",
        "df_train = df_train.loc[:, [\"Utterance\", \"Target\"]].rename(columns={\"Target\": \"label\"})\n",
        "df_eval = df_eval.loc[:, [\"Utterance\", \"Target\"]].rename(columns={\"Target\": \"label\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zxN5atGQDpz"
      },
      "outputs": [],
      "source": [
        "def roberta_tokenize(data):\n",
        "    return roberta_tokenizer(\n",
        "        data[\"Utterance\"],\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "\n",
        "train_set = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
        "eval_set = Dataset.from_pandas(df_eval.reset_index(drop=True))\n",
        "\n",
        "train_set = train_set.map(roberta_tokenize, batched=True, batch_size=len(train_set))\n",
        "eval_set = eval_set.map(roberta_tokenize, batched=True, batch_size=len(eval_set))\n",
        "\n",
        "train_set.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "eval_set.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sHLXyvHysyi"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uLtQqBDq_Rr"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"f1-macro\": f1, \"accuracy\": acc}\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "model = RobertaForSequenceClassification.from_pretrained(MODEL, num_labels=label_size)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=TRAIN_ARGS,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=eval_set,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z0IrePhOh8V"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJFKEDKxY8bU"
      },
      "outputs": [],
      "source": [
        "model_eval = trainer.evaluate()\n",
        "print(f\"Accuracy: {model_eval['eval_accuracy']:.5f}\")\n",
        "print(f\"F1-macro: {model_eval['eval_f1-macro']:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "R8u-LFGvT0YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roberta_tokenize(data):\n",
        "    return roberta_tokenizer(\n",
        "        data[\"Utterance\"],\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "\n",
        "test_csv = pd.read_csv(join_path(\"data\", \"test.csv\"))\n",
        "df_test = test_csv.loc[:, \"Utterance\"].to_frame()\n",
        "\n",
        "test_set = Dataset.from_pandas(df_test.reset_index(drop=True))\n",
        "test_set = test_set.map(roberta_tokenize, batched=True, batch_size=len(test_set))\n",
        "test_set.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
      ],
      "metadata": {
        "id": "4Qc8XeQuTzdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_set):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    test_predict = []\n",
        "    for data in tqdm(test_set):\n",
        "        input_id = data[\"input_ids\"].unsqueeze(0).to(DEVICE)\n",
        "        mask = data[\"attention_mask\"].unsqueeze(0).to(DEVICE)\n",
        "        output = model(input_id, mask)\n",
        "        y_pred = output.logits\n",
        "        test_predict += y_pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "    return test_predict\n",
        "     \n",
        "preds = predict(model, test_set)\n",
        "preds = label_encoder.decode(preds)\n",
        "     \n",
        "test_csv[\"Target\"] = preds\n",
        "result_csv = test_csv.loc[:, [\"ID\", \"Target\"]]\n",
        "result_csv.head(10)"
      ],
      "metadata": {
        "id": "ydgriWQ7RGWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}